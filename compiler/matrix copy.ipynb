{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum, auto\n",
    "from typing import *\n",
    "\n",
    "\n",
    "class Keyword(Enum):\n",
    "    WHILE = auto()\n",
    "    WHILE_NOT = auto()\n",
    "    IF = auto()\n",
    "    IF_NOT = auto()\n",
    "    READ = auto()\n",
    "    WRITE = auto()\n",
    "    COMMAND_END = auto()\n",
    "    CONDITION_START = auto()\n",
    "    CONDITION_END = auto()\n",
    "    BLOCK_START = auto()\n",
    "    BLOCK_END = auto()\n",
    "    PLUS = auto()\n",
    "    MINUS = auto()\n",
    "    MUL = auto()\n",
    "    DIV = auto()\n",
    "    DEFINITION = auto()\n",
    "    OPEN_PARENTHESIS = auto()\n",
    "    CLOSE_PARENTHESIS = auto()\n",
    "    ARRAY_DELIMITER = auto() #\n",
    "    ARRAY = auto() #\n",
    "    ARRAY_INDEX = auto() #\n",
    "\n",
    "\n",
    "KEYWORD_BY_NAMES: Dict[str, Keyword] = {\n",
    "    \"while\": Keyword.WHILE,\n",
    "    \"whilenot\": Keyword.WHILE_NOT,\n",
    "    \"if\": Keyword.IF,\n",
    "    \"ifnot\": Keyword.IF_NOT,\n",
    "    \"read>\": Keyword.READ,\n",
    "    \"write>\": Keyword.WRITE,\n",
    "    \";\": Keyword.COMMAND_END,\n",
    "    \"[\": Keyword.CONDITION_START,\n",
    "    \"]\": Keyword.CONDITION_END,\n",
    "    \"{\": Keyword.BLOCK_START,\n",
    "    \"}\": Keyword.BLOCK_END,\n",
    "    \"+\": Keyword.PLUS,\n",
    "    \"-\": Keyword.MINUS,\n",
    "    \"*\": Keyword.MUL,\n",
    "    \"/\": Keyword.DIV,\n",
    "    \"=\": Keyword.DEFINITION,\n",
    "    \"(\": Keyword.OPEN_PARENTHESIS,\n",
    "    \")\": Keyword.CLOSE_PARENTHESIS,\n",
    "    \"|\": Keyword.ARRAY, #\n",
    "    \",\": Keyword.ARRAY_DELIMITER, #\n",
    "    \"#\": Keyword.ARRAY_INDEX, #\n",
    "}\n",
    "\n",
    "KEYWORD_NAMES: Dict[Keyword, str] = {v: k for k, v in KEYWORD_BY_NAMES.items()}\n",
    "\n",
    "class TokenType(Enum):\n",
    "    NUMBER = auto()\n",
    "    WORD = auto()\n",
    "    KEYWORD = auto()\n",
    "\n",
    "\n",
    "# file row col\n",
    "Location = Tuple[str, int, int]\n",
    "\n",
    "@dataclass\n",
    "class Token:\n",
    "    typ: TokenType\n",
    "    text: str\n",
    "    loc: Location\n",
    "    value: Union[float, str, Keyword]\n",
    "\n",
    "\n",
    "class InstructionType(Enum):\n",
    "    ADD = auto()\n",
    "    SUB = auto()\n",
    "    MUL = auto()\n",
    "    DIV = auto()\n",
    "    READ = auto()\n",
    "    WRITE = auto()\n",
    "    GOTO_IF_NOT = auto()\n",
    "    GOTO_IF = auto()\n",
    "    GOTO = auto()\n",
    "    COPY = auto()\n",
    "    ARRAY = auto() #\n",
    "\n",
    "\n",
    "INSTRUCTION_BY_NAMES: Dict[str, InstructionType] = {\n",
    "    \"ADD\": InstructionType.ADD,\n",
    "    \"SUB\": InstructionType.SUB,\n",
    "    \"MUL\": InstructionType.MUL,\n",
    "    \"DIV\": InstructionType.DIV,\n",
    "    \"READ\": InstructionType.READ,\n",
    "    \"WRITE\": InstructionType.WRITE,\n",
    "    \"GOTOIFNOT\": InstructionType.GOTO_IF_NOT,\n",
    "    \"GOTOIF\": InstructionType.GOTO_IF,\n",
    "    \"GOTO\": InstructionType.GOTO,\n",
    "    \"COPY\": InstructionType.COPY,\n",
    "    \"ARRAY\": InstructionType.ARRAY, #\n",
    "}\n",
    "\n",
    "INSTRUCTION_NAMES: Dict[InstructionType, str] = {v: k for k, v in INSTRUCTION_BY_NAMES.items()}\n",
    "\n",
    "@dataclass\n",
    "class Instruction:\n",
    "    typ: InstructionType\n",
    "    args: List[Union[float, str]]\n",
    "\n",
    "def token_priority(token: Token) -> int:\n",
    "    if token.typ != TokenType.KEYWORD:\n",
    "        return -2\n",
    "\n",
    "    v = token.value\n",
    "    if v == Keyword.OPEN_PARENTHESIS or v == Keyword.CLOSE_PARENTHESIS:\n",
    "        return 0\n",
    "    elif v == Keyword.PLUS or v == Keyword.MINUS:\n",
    "        return 1\n",
    "    elif v == Keyword.MUL or v == Keyword.DIV:\n",
    "        return 2\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "\n",
    "def find_col(line: str, start: int, predicate: Callable[[str], bool]) -> int:\n",
    "    while start < len(line) and not predicate(line[start]):\n",
    "        start += 1\n",
    "    return start\n",
    "\n",
    "\n",
    "def lex_lines(file_path: str, lines: List[str]) -> Generator[Token, None, None]:\n",
    "    row = 0\n",
    "    while row < len(lines):\n",
    "        line = lines[row]\n",
    "        col = find_col(line, 0, lambda x: not x.isspace())\n",
    "        col_end = col\n",
    "        while col < len(line):\n",
    "            if line[col].isalnum():\n",
    "                col_end = find_col(line, col, lambda x: not (x.isalnum() or x == \">\" or x == \".\" or x == \"#\")) #\n",
    "            elif line[col] in KEYWORD_BY_NAMES:\n",
    "                col_end = col + 1\n",
    "\n",
    "            loc = (file_path, row + 1, col + 1)\n",
    "            text_of_token = line[col:col_end]\n",
    "\n",
    "            try:\n",
    "                yield Token(TokenType.NUMBER, text_of_token, loc, float(text_of_token))\n",
    "            except ValueError:\n",
    "                if text_of_token in KEYWORD_BY_NAMES:\n",
    "                    yield Token(TokenType.KEYWORD, text_of_token, loc, KEYWORD_BY_NAMES[text_of_token])\n",
    "                else:\n",
    "                    yield Token(TokenType.WORD, text_of_token, loc, text_of_token)\n",
    "\n",
    "            col = find_col(line, col_end, lambda x: not x.isspace())\n",
    "        row += 1\n",
    "\n",
    "\n",
    "def lex_file(file_path: str) -> List[Token]:\n",
    "    with open(file_path, \"r\", encoding='utf-8') as f:\n",
    "        return [token for token in lex_lines(file_path, f.readlines())]\n",
    "\n",
    "\n",
    "def compile_error(text: str):\n",
    "    print(\"Compilation error:\")\n",
    "    print(text)\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "def expected(loc: Location, after: str, exp: str, found: str):\n",
    "    compile_error(\n",
    "        f\"{loc[0]}:{loc[1]}:{loc[2]}: after {after} expected {exp}, but found {found}\")\n",
    "\n",
    "\n",
    "def expected_command_end(loc: Location, after: str, found: str):\n",
    "    expected(loc, after, f\"'{KEYWORD_NAMES[Keyword.COMMAND_END]}'\", found)\n",
    "\n",
    "\n",
    "def convert_to_postfix(tokens: List[Token]) -> List[Token]:\n",
    "    ops = []\n",
    "    res = []\n",
    "\n",
    "    # Does not checks if tokens are correct\n",
    "    for token in tokens:\n",
    "        if token.typ == TokenType.WORD or token.typ == TokenType.NUMBER:\n",
    "            res.append(token)\n",
    "            continue\n",
    "\n",
    "        if token.value == Keyword.OPEN_PARENTHESIS:\n",
    "            ops.append(token)\n",
    "        elif token.value == Keyword.CLOSE_PARENTHESIS:\n",
    "            while ops[-1].value != Keyword.OPEN_PARENTHESIS:\n",
    "                res.append(ops.pop())\n",
    "            ops.pop()\n",
    "        else:\n",
    "            while len(ops) != 0 and token_priority(ops[-1]) >= token_priority(token):\n",
    "                res.append(ops.pop())\n",
    "            ops.append(token)\n",
    "\n",
    "    while len(ops) != 0:\n",
    "        res.append(ops.pop())\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def eval_expression(tokens: List[Token], varc: int) -> Tuple[List[Instruction], str, int]:\n",
    "    inst = []\n",
    "    values = []\n",
    "\n",
    "    if len(tokens) == 1:\n",
    "        t = tokens[0]\n",
    "        if t.typ != TokenType.WORD and t.typ != TokenType.NUMBER:\n",
    "            expected(t.loc, \"expression start\", \"variable or number\", str(t.typ))\n",
    "        inst.append(Instruction(InstructionType.COPY, [t.value, \"tmp\"]))\n",
    "        return inst, f\"t{varc - 1}\", varc + 1\n",
    "\n",
    "    for token in tokens:\n",
    "        if token.typ == TokenType.NUMBER or token.typ == TokenType.WORD:\n",
    "            values.append(token)\n",
    "            continue\n",
    "\n",
    "        right_value = values.pop().value\n",
    "        left_value = values.pop().value\n",
    "\n",
    "        var = f\"t{varc}\"\n",
    "        varc += 1\n",
    "        var_t = Token(TokenType.WORD, var, (\"tmp\", -1, -1), var)\n",
    "\n",
    "        args = [left_value, right_value, var]\n",
    "        if token.value == Keyword.PLUS:\n",
    "            inst.append(Instruction(InstructionType.ADD, args))\n",
    "            values.append(var_t)\n",
    "        elif token.value == Keyword.MINUS:\n",
    "            inst.append(Instruction(InstructionType.SUB, args))\n",
    "            values.append(var_t)\n",
    "        elif token.value == Keyword.MUL:\n",
    "            inst.append(Instruction(InstructionType.MUL, args))\n",
    "            values.append(var_t)\n",
    "        elif token.value == Keyword.DIV:\n",
    "            inst.append(Instruction(InstructionType.DIV, args))\n",
    "            values.append(var_t)\n",
    "        else:\n",
    "            expected(token.loc, \"expression part\", \"expression\", token.text)\n",
    "\n",
    "    return inst, f\"t{varc - 1}\", varc\n",
    "\n",
    "\n",
    "def parse_expression(i: int, tokens: List[Token], varc: int) -> Tuple[List[Instruction], int, int]:\n",
    "    expr_tokens = []\n",
    "\n",
    "    while i < len(tokens):\n",
    "        t = tokens[i]\n",
    "        i += 1\n",
    "\n",
    "        if t.typ == TokenType.KEYWORD:\n",
    "            if t.value == Keyword.CONDITION_START:\n",
    "                continue\n",
    "            if t.value == Keyword.COMMAND_END or t.value == Keyword.CONDITION_END:\n",
    "                break\n",
    "\n",
    "        expr_tokens.append(t)\n",
    "\n",
    "    if i > len(tokens):\n",
    "        expected(tokens[i - 1].loc, \"expression\",\n",
    "                 f\"{KEYWORD_NAMES[Keyword.COMMAND_END]} or {KEYWORD_NAMES[Keyword.CONDITION_END]}\",\n",
    "                 f\"{tokens[i - 1].text}\")\n",
    "\n",
    "    expr_tokens = convert_to_postfix(expr_tokens)\n",
    "    inst, r_tmp, varc = eval_expression(expr_tokens, varc)\n",
    "\n",
    "    return inst, i, varc - 1\n",
    "\n",
    "\n",
    "def parse_condition(with_not: bool, i: int, tokens: List[Token], varc: int) -> Tuple[List[Instruction], int, int]:\n",
    "    expr = parse_expression(i, tokens, varc)\n",
    "    inst = expr[0]\n",
    "    varc = expr[2]\n",
    "\n",
    "    var = f\"t{varc}\"\n",
    "    varc += 1\n",
    "    inst[-1].args[-1] = var\n",
    "\n",
    "    i = expr[1]\n",
    "\n",
    "    if with_not:\n",
    "        inst.append(Instruction(InstructionType.GOTO_IF, [var]))\n",
    "    else:\n",
    "        inst.append(Instruction(InstructionType.GOTO_IF_NOT, [var]))\n",
    "\n",
    "    return inst, i, varc\n",
    "\n",
    "\n",
    "def parse_program_from_tokens(tokens: List[Token]) -> List[Instruction]:\n",
    "    i = 0\n",
    "    varc = 1\n",
    "    instructions: List[Instruction] = []\n",
    "    back_stack: List[Tuple[int, Keyword]] = []\n",
    "    l = len(tokens)\n",
    "    while i < l:\n",
    "        t = tokens[i]\n",
    "        i += 1\n",
    "\n",
    "        if t.typ == TokenType.NUMBER:\n",
    "            if i >= l:\n",
    "                expected_command_end(t.loc, \"bare number\", \"nothing\")\n",
    "            tn = tokens[i]\n",
    "            if tn.value == Keyword.COMMAND_END:\n",
    "                i += 1\n",
    "                continue\n",
    "            expected_command_end(tn.loc, \"bare number\", f\"'{tn.text}'\")\n",
    "        elif t.typ == TokenType.WORD:\n",
    "            if i >= l:\n",
    "                expected(t.loc, f\"'{KEYWORD_NAMES[t.value]}'\", f\"{KEYWORD_NAMES[Keyword.DEFINITION]} or expression\",\n",
    "                         \"nothing\")\n",
    "            tn = tokens[i]\n",
    "            i += 1\n",
    "\n",
    "            if tn.typ == TokenType.KEYWORD:\n",
    "                if tn.value == Keyword.DEFINITION:\n",
    "                    tnn = tokens[i]\n",
    "                    if tnn.value == Keyword.ARRAY:\n",
    "                        i += 1\n",
    "                        args: List[Union[float, str]] = [t.text]\n",
    "\n",
    "                        while tokens[i].value != Keyword.ARRAY:\n",
    "                            if tokens[i].value == Keyword.ARRAY_DELIMITER:\n",
    "                                i += 1\n",
    "                                continue\n",
    "                            args.append(tokens[i].value)\n",
    "                            i += 1\n",
    "                        i += 2\n",
    "\n",
    "                        instructions.append(Instruction(InstructionType.ARRAY, args))\n",
    "                    else:\n",
    "                        exps = parse_expression(i, tokens, varc)\n",
    "                        instructions += exps[0]\n",
    "                        instructions[-1].args[-1] = t.text\n",
    "                        i += exps[1] - i\n",
    "                        varc += exps[2] - varc\n",
    "                else:\n",
    "                    if i >= l:\n",
    "                        expected_command_end(t.loc, \"bare variable\", \"nothing\")\n",
    "                    else:\n",
    "                        tn = tokens[i]\n",
    "                        i += 1\n",
    "                        expected_command_end(tn.loc, \"bare variable\", f\"'{tn.text}'\")\n",
    "            else:\n",
    "                expected(t.loc, f\"'{KEYWORD_NAMES[t.value]}'\", \"keyword\", f\"{tn.text}\")\n",
    "        else:\n",
    "            if t.value == Keyword.IF or \\\n",
    "                    t.value == Keyword.WHILE or \\\n",
    "                    t.value == Keyword.IF_NOT or \\\n",
    "                    t.value == Keyword.WHILE_NOT:\n",
    "\n",
    "                with_not = t.value == Keyword.IF_NOT or t.value == Keyword.WHILE_NOT\n",
    "                cond = parse_condition(with_not, i, tokens, varc)\n",
    "                instructions += cond[0]\n",
    "                i += cond[1] - i\n",
    "                varc += cond[2] - varc\n",
    "\n",
    "                i += 1\n",
    "\n",
    "                back_stack.append((len(instructions) - 1, t.value))\n",
    "            elif t.value == Keyword.BLOCK_END:\n",
    "                r = back_stack.pop()\n",
    "\n",
    "                if r[1] == Keyword.IF or r[1] == Keyword.IF_NOT:\n",
    "                    instructions[r[0]].args.append(str(len(instructions)))\n",
    "                elif r[1] == Keyword.WHILE or r[1] == Keyword.WHILE_NOT:\n",
    "                    instructions.append(Instruction(InstructionType.GOTO, [str(r[0] - 1)]))\n",
    "                    instructions[r[0]].args.append(len(instructions))\n",
    "                else:\n",
    "                    compile_error(f\"{t.loc} unsupported back keyword: {t.value}\")\n",
    "            elif t.value == Keyword.READ:\n",
    "                if i >= l:\n",
    "                    expected(t.loc, f\"'{KEYWORD_NAMES[t.value]}'\", \"variable\", \"nothing\")\n",
    "                tn = tokens[i]\n",
    "                i += 1\n",
    "                if i >= l:\n",
    "                    expected_command_end(tn.loc, \"variable\", \"nothing\")\n",
    "                if tn.typ != TokenType.WORD:\n",
    "                    expected(t.loc, f\"'{KEYWORD_NAMES[t.value]}'\", \"variable\", f\"'{t.text}'\")\n",
    "                instructions.append(Instruction(InstructionType.READ, [tn.value]))\n",
    "                i += 1\n",
    "            elif t.value == Keyword.WRITE:\n",
    "                if i >= l:\n",
    "                    expected(t.loc, f\"'{KEYWORD_NAMES[t.value]}'\", \"variable\", \"nothing\")\n",
    "                tn = tokens[i]\n",
    "                i += 1\n",
    "                if i >= l:\n",
    "                    expected_command_end(tn.loc, \"variable\", \"nothing\")\n",
    "                if tn.typ != TokenType.WORD and tn.typ != TokenType.NUMBER:\n",
    "                    expected(t.loc, f\"'{KEYWORD_NAMES[t.value]}'\", \"variable\", f\"'{t.text}'\")\n",
    "                instructions.append(Instruction(InstructionType.WRITE, [tn.value]))\n",
    "                i += 1\n",
    "            else:\n",
    "                assert False, f\"Parsing keyword {KEYWORD_NAMES[t.value]} not implemented\"\n",
    "\n",
    "    return instructions\n",
    "\n",
    "\n",
    "def parse_program_from_file(file_path: str) -> List[Instruction]:\n",
    "    tokens = lex_file(file_path)\n",
    "    return parse_program_from_tokens(tokens)\n",
    "\n",
    "\n",
    "def write_instruction(file_path: str, inst: List[Instruction]):\n",
    "    with open(file_path, \"w\") as f:\n",
    "        for i in inst:\n",
    "            f.write(f\"{INSTRUCTION_NAMES[i.typ]} \")\n",
    "            f.write(\" \".join([str(a) for a in i.args]))\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "\n",
    "def is_var(text: str) -> bool:\n",
    "    return not text.replace(\".\", \"\", 1).isnumeric()\n",
    "\n",
    "\n",
    "def is_array(text: str) -> bool: #\n",
    "    return text.find(\"#\") >= 0\n",
    "\n",
    "\n",
    "def read_var(text: str, vs: Dict[str, float], ar: Dict[str, List[float]]) -> float: #\n",
    "    if not is_var(text):\n",
    "        return float(text)\n",
    "\n",
    "    if is_array(text):\n",
    "        name, index = text.split(\"#\", 1)\n",
    "        index = int(read_var(index, vs, ar))\n",
    "        return ar[name][index]\n",
    "    else:\n",
    "        return vs[text]\n",
    "\n",
    "\n",
    "def write_var(text: str, val: float, vs: Dict[str, float], ar: Dict[str, List[float]]): #\n",
    "    if is_array(text):\n",
    "        name, index = text.split(\"#\")\n",
    "        index = int(read_var(index, vs, ar))\n",
    "        ar[name][index] = val\n",
    "    else:\n",
    "        vs[text] = val\n",
    "\n",
    "\n",
    "def interpret_file(file_path: str):\n",
    "    with open(file_path, \"r\", encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        i: int = 0\n",
    "        vs: Dict[str, float] = {}\n",
    "        ar: Dict[str, List[float]] = {}\n",
    "        while i < len(lines):\n",
    "            ins = lines[i].replace(\"\\n\", \"\").split(\" \")\n",
    "\n",
    "            if ins[0] == INSTRUCTION_NAMES[InstructionType.READ]:\n",
    "                v = float(input(\"> \"))\n",
    "                write_var(ins[1], v, vs, ar)\n",
    "                i += 1\n",
    "            elif ins[0] == INSTRUCTION_NAMES[InstructionType.WRITE]:\n",
    "                v = ins[1]\n",
    "                if is_var(ins[1]):\n",
    "                    v = read_var(v, vs, ar)\n",
    "                print(v)\n",
    "                i += 1\n",
    "            elif ins[0] == INSTRUCTION_NAMES[InstructionType.ARRAY]: #\n",
    "                elems = []\n",
    "                for a in ins[2:]:\n",
    "                    if is_var(a):\n",
    "                        a = read_var(a, vs, ar)\n",
    "                    elems.append(float(a))\n",
    "                ar[ins[1]] = elems\n",
    "                i += 1\n",
    "            elif ins[0] == INSTRUCTION_NAMES[InstructionType.COPY]:\n",
    "                a, b = ins[1], ins[2]\n",
    "                if is_var(a):\n",
    "                    a = read_var(a, vs, ar)\n",
    "                write_var(b, float(a), vs, ar)\n",
    "                i += 1\n",
    "            elif ins[0] == INSTRUCTION_NAMES[InstructionType.GOTO_IF]:\n",
    "                v = ins[1]\n",
    "                if is_var(ins[1]):\n",
    "                    v = read_var(v, vs, ar)\n",
    "                if float(v) > 0:\n",
    "                    i = int(ins[2])\n",
    "                else:\n",
    "                    i += 1\n",
    "            elif ins[0] == INSTRUCTION_NAMES[InstructionType.GOTO_IF_NOT]:\n",
    "                v = ins[1]\n",
    "                if is_var(ins[1]):\n",
    "                    v = read_var(v, vs, ar)\n",
    "                if not float(v) > 0:\n",
    "                    i = int(ins[2])\n",
    "                else:\n",
    "                    i += 1\n",
    "            elif ins[0] == INSTRUCTION_NAMES[InstructionType.GOTO]:\n",
    "                i = int(ins[1])\n",
    "            elif ins[0] == INSTRUCTION_NAMES[InstructionType.ADD]:\n",
    "                a, b, c = ins[1], ins[2], ins[3]\n",
    "                if is_var(a):\n",
    "                    a = read_var(a, vs, ar)\n",
    "                if is_var(b):\n",
    "                    b = read_var(b, vs, ar)\n",
    "                res = float(a) + float(b)\n",
    "                write_var(c, res, vs, ar)\n",
    "                i += 1\n",
    "            elif ins[0] == INSTRUCTION_NAMES[InstructionType.SUB]:\n",
    "                a, b, c = ins[1], ins[2], ins[3]\n",
    "                if is_var(a):\n",
    "                    a = read_var(a, vs, ar)\n",
    "                if is_var(b):\n",
    "                    b = read_var(b, vs, ar)\n",
    "                res = float(a) - float(b)\n",
    "                write_var(c, res, vs, ar)\n",
    "                i += 1\n",
    "            elif ins[0] == INSTRUCTION_NAMES[InstructionType.MUL]:\n",
    "                a, b, c = ins[1], ins[2], ins[3]\n",
    "                if is_var(a):\n",
    "                    a = read_var(a, vs, ar)\n",
    "                if is_var(b):\n",
    "                    b = read_var(b, vs, ar)\n",
    "                res = float(a) * float(b)\n",
    "                write_var(c, res, vs, ar)\n",
    "                i += 1\n",
    "            elif ins[0] == INSTRUCTION_NAMES[InstructionType.DIV]:\n",
    "                a, b, c = ins[1], ins[2], ins[3]\n",
    "                if is_var(a):\n",
    "                    a = read_var(a, vs, ar)\n",
    "                if is_var(b):\n",
    "                    b = read_var(b, vs, ar)\n",
    "                res = float(a) / float(b)\n",
    "                write_var(c, res, vs, ar)\n",
    "                i += 1\n",
    "            else:\n",
    "                assert False, f\"Not implemented {ins[0]}\"\n",
    "\n",
    "\n",
    "if __name__ == '__main__' and '__file__' in globals():\n",
    "    argv = sys.argv\n",
    "    assert len(argv) > 1, \"Please provide command & file\"\n",
    "    compiler_name, *argv = argv\n",
    "\n",
    "    command: str = argv[0]\n",
    "    file: str = argv[1]\n",
    "\n",
    "    if command == \"com\":\n",
    "        if not file.endswith(\".my\"):\n",
    "            compile_error(\"Invalid file extension, expected .my\")\n",
    "\n",
    "        print(f\"Compiling {file} using {compiler_name}...\\n\")\n",
    "        inst = parse_program_from_file(file)\n",
    "        write_instruction(file + \"m\", inst)\n",
    "    elif command == \"run\":\n",
    "        if not file.endswith(\".mym\"):\n",
    "            compile_error(\"Invalid file extension, expected .mym\")\n",
    "\n",
    "        print(f\"Running {file} using {compiler_name}...\\n\")\n",
    "\n",
    "        interpret_file(file)\n",
    "    elif command == \"cnr\":\n",
    "        if not file.endswith(\".my\"):\n",
    "            compile_error(\"Invalid file extension, expected .my\")\n",
    "\n",
    "        print(f\"Compiling {file} using {compiler_name}...\\n\")\n",
    "        inst = parse_program_from_file(file)\n",
    "\n",
    "        file += \"m\"\n",
    "        write_instruction(file, inst)\n",
    "\n",
    "        print(f\"Running {file} using {compiler_name}...\\n\")\n",
    "\n",
    "        interpret_file(file)\n",
    "    else:\n",
    "        print(f\"Unknown command '{command}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e4f93ec01850e5a04c88373eedc4088b21809952ed00f2c5f268eb2f2380b3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
